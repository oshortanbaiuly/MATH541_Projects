{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a8d3a9b6",
      "metadata": {
        "id": "a8d3a9b6"
      },
      "source": [
        "# MATH541 Data Analysis and Statistical Learning Project 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f5c55a1",
      "metadata": {
        "id": "3f5c55a1"
      },
      "source": [
        "## Author: Olzhas Shortanbaiuly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2062e0f6",
      "metadata": {
        "id": "2062e0f6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a26eb219",
      "metadata": {
        "id": "a26eb219"
      },
      "source": [
        "My dataset was \"Ecoli data set\" involving the protein localization sites. It can be accessed in http://archive.ics.uci.edu/ml/datasets/Ecoli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9ba5935",
      "metadata": {
        "id": "b9ba5935",
        "outputId": "a18d605d-bd34-44e9-d5b9-3445b247e831"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\olzhas.shortanbaiuly\\AppData\\Local\\Temp\\ipykernel_3880\\1165469454.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['SITE'][i] = 'ncp' #'ncp' stands for 'not cp'\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/oshortanbaiuly/MATH542_proj2/main/ecoli.csv')\n",
        "data.set_index('SEQUENCE_NAME', inplace=True)\n",
        "for i in range(len(data.SITE)):\n",
        "    if data['SITE'][i] != 'cp':\n",
        "        data['SITE'][i] = 'ncp' #'ncp' stands for 'not cp'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8aa2cc3",
      "metadata": {
        "id": "e8aa2cc3",
        "outputId": "36e5530b-037c-4834-ee01-dcabc8c2cb59"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MCG</th>\n",
              "      <th>GVH</th>\n",
              "      <th>LIP</th>\n",
              "      <th>CHG</th>\n",
              "      <th>AAC</th>\n",
              "      <th>ALM1</th>\n",
              "      <th>ALM2</th>\n",
              "      <th>SITE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SEQUENCE_NAME</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AAT_ECOLI</th>\n",
              "      <td>0.49</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.35</td>\n",
              "      <td>cp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACEA_ECOLI</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.44</td>\n",
              "      <td>cp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACEK_ECOLI</th>\n",
              "      <td>0.56</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.46</td>\n",
              "      <td>cp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACKA_ECOLI</th>\n",
              "      <td>0.59</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.36</td>\n",
              "      <td>cp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADI_ECOLI</th>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.35</td>\n",
              "      <td>cp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                MCG   GVH   LIP  CHG   AAC  ALM1  ALM2 SITE\n",
              "SEQUENCE_NAME                                              \n",
              "AAT_ECOLI      0.49  0.29  0.48  0.5  0.56  0.24  0.35   cp\n",
              "ACEA_ECOLI     0.07  0.40  0.48  0.5  0.54  0.35  0.44   cp\n",
              "ACEK_ECOLI     0.56  0.40  0.48  0.5  0.49  0.37  0.46   cp\n",
              "ACKA_ECOLI     0.59  0.49  0.48  0.5  0.52  0.45  0.36   cp\n",
              "ADI_ECOLI      0.23  0.32  0.48  0.5  0.55  0.25  0.35   cp"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09813669",
      "metadata": {
        "id": "09813669"
      },
      "source": [
        "### 1. If you have a large database (N >> 20p), then divide your data into 3 parts: the training set, the validation, and the test set. Decide which ratio train : validation : test to use and explain your motives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37adf264",
      "metadata": {
        "id": "37adf264",
        "outputId": "fd9d3785-d222-4316-9447-be478cd1ee6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(336, 8)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de7c080e",
      "metadata": {
        "id": "de7c080e"
      },
      "source": [
        "Since there are 336 points in the dataset and it is a considerably small amount, we can allocate 50% of the data to train the model. Other than that, 25% of data is used to test the model and 25% of data is taken as a validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3311e119",
      "metadata": {
        "id": "3311e119"
      },
      "outputs": [],
      "source": [
        "# Separate features and target variable\n",
        "X = data.drop('SITE', axis=1)\n",
        "y = data['SITE']\n",
        "\n",
        "# Split data into training, test and validation sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size = 2/3, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "431896c4",
      "metadata": {
        "id": "431896c4"
      },
      "source": [
        "## 2. Standardize all you features X1, ..., Xp. Standardization of feature Xi meansreplacing its values with $\\frac{X_i - \\bar{X_i}}{\\sqrt{\\bar{X_{i}^2}-(\\bar{X_i})^2}}$ where $\\bar{f}$ denotes averaging over your training sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d6eb9c8",
      "metadata": {
        "id": "5d6eb9c8"
      },
      "outputs": [],
      "source": [
        "# Transform the training, validation, and test sets using the fitted scaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_std = scaler.transform(X_train)\n",
        "X_valid_std = scaler.transform(X_valid)\n",
        "X_test_std = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e719df0",
      "metadata": {
        "id": "0e719df0"
      },
      "source": [
        "## 3. Choose 3-5 candidates for C : C1, C2, ..., C5 and find weight vectors (using only training set) for Model I (SVM model with linear kernel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14f90294",
      "metadata": {
        "id": "14f90294",
        "outputId": "0ebe6d37-f592-49c9-e1cc-2ca4159e16ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weight vector for C = 0.1:\n",
            "[[0.45459437 0.69906646 0.00482766 0.01066491 0.27703884 1.10063302\n",
            "  0.01969326]]\n",
            "\n",
            "Weight vector for C = 1:\n",
            "[[ 6.12386491e-01  8.17731699e-01  5.55111512e-17  0.00000000e+00\n",
            "   2.91512302e-01  2.33019328e+00 -7.94256669e-01]]\n",
            "\n",
            "Weight vector for C = 10:\n",
            "[[ 7.06160956e-01  8.41713142e-01  4.44089210e-16  1.77635684e-15\n",
            "   1.53280955e-01  3.48325286e+00 -1.58982448e+00]]\n",
            "\n",
            "Weight vector for C = 100:\n",
            "[[ 6.78633426e-01  8.21703797e-01 -2.84217094e-14 -2.66453526e-14\n",
            "   1.71165118e-01  3.47537222e+00 -1.67458070e+00]]\n",
            "\n",
            "Weight vector for C = 1000:\n",
            "[[ 5.70305218e-01  9.32893535e-01 -9.94759830e-13 -3.69482223e-13\n",
            "   3.11661110e-01  4.32394479e+00 -2.33904883e+00]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Candidate C values\n",
        "C_values = [0.1, 1, 10, 100, 1000]\n",
        "\n",
        "# Create an empty list to store the models\n",
        "models = []\n",
        "\n",
        "# Train a model for each candidate C value\n",
        "for C in C_values:\n",
        "    # Create an SVM model with a linear kernel and the current C value\n",
        "    model = SVC(kernel='linear', C=C, random_state=1)\n",
        "    model.fit(X_train_std, y_train)\n",
        "    models.append(model)\n",
        "\n",
        "# Print weight vectors for each model\n",
        "for i, model in enumerate(models):\n",
        "    print(f\"Weight vector for C = {C_values[i]}:\\n{model.coef_}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "100111dd",
      "metadata": {
        "id": "100111dd"
      },
      "source": [
        "## 4. For C = $C_i$, estimate the following values on the training set: (a) percent of incorrectly classified examples (error rate) (b) precision and recall (c) the number of support vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "146578c0",
      "metadata": {
        "id": "146578c0",
        "outputId": "2e7731ee-8a3c-4a3e-856e-95579d45fa9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For C = 0.1:\n",
            "  (a) Error rate: 0.05\n",
            "  (b) Precision: 0.97, Recall: 0.95\n",
            "  (c) Number of support vectors: 49\n",
            "\n",
            "For C = 1:\n",
            "  (a) Error rate: 0.04\n",
            "  (b) Precision: 0.98, Recall: 0.96\n",
            "  (c) Number of support vectors: 28\n",
            "\n",
            "For C = 10:\n",
            "  (a) Error rate: 0.04\n",
            "  (b) Precision: 0.96, Recall: 0.97\n",
            "  (c) Number of support vectors: 20\n",
            "\n",
            "For C = 100:\n",
            "  (a) Error rate: 0.04\n",
            "  (b) Precision: 0.97, Recall: 0.97\n",
            "  (c) Number of support vectors: 20\n",
            "\n",
            "For C = 1000:\n",
            "  (a) Error rate: 0.03\n",
            "  (b) Precision: 0.98, Recall: 0.97\n",
            "  (c) Number of support vectors: 18\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Iterate over the trained models and calculate the metrics\n",
        "for i, model in enumerate(models):\n",
        "    # Predict the classes using the current model\n",
        "    y_pred = model.predict(X_train_std)\n",
        "\n",
        "    # Calculate the error rate\n",
        "    error_rate = 1 - accuracy_score(y_train, y_pred)\n",
        "\n",
        "    # Calculate the precision and recall\n",
        "    precision = precision_score(y_train, y_pred, pos_label='ncp')\n",
        "    recall = recall_score(y_train, y_pred, pos_label='ncp')\n",
        "\n",
        "    # Get the number of support vectors\n",
        "    n_support_vectors = len(model.support_)\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"For C = {C_values[i]}:\")\n",
        "    print(f\"  (a) Error rate: {error_rate:.2f}\")\n",
        "    print(f\"  (b) Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
        "    print(f\"  (c) Number of support vectors: {n_support_vectors}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43d93f1b",
      "metadata": {
        "id": "43d93f1b"
      },
      "source": [
        "## 5. For C = Ci, estimate the following values on the validation set: (a) percent of incorrectly classified examples (error rate) (b) precision and recall (c) Choose proper β (natural to your problem) and estimate $F_β$ measure: $F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{\\beta^2 \\cdot precision + recall}$. Collect all your findings into a table. Using those estimations, choose the best value $C = C_{i}^∗$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "215fb0fd",
      "metadata": {
        "id": "215fb0fd",
        "outputId": "26c5cc87-a298-4366-dce5-c75aebb83bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For C = 0.1:\n",
            "  (a) Error rate on validation set: 0.02\n",
            "  (b) Precision: 0.96, Recall: 1.00\n",
            "  (c) F_0.5 measure: 0.97\n",
            "\n",
            "For C = 1:\n",
            "  (a) Error rate on validation set: 0.02\n",
            "  (b) Precision: 0.96, Recall: 1.00\n",
            "  (c) F_0.5 measure: 0.97\n",
            "\n",
            "For C = 10:\n",
            "  (a) Error rate on validation set: 0.02\n",
            "  (b) Precision: 0.96, Recall: 1.00\n",
            "  (c) F_0.5 measure: 0.97\n",
            "\n",
            "For C = 100:\n",
            "  (a) Error rate on validation set: 0.02\n",
            "  (b) Precision: 0.96, Recall: 1.00\n",
            "  (c) F_0.5 measure: 0.97\n",
            "\n",
            "For C = 1000:\n",
            "  (a) Error rate on validation set: 0.04\n",
            "  (b) Precision: 0.94, Recall: 1.00\n",
            "  (c) F_0.5 measure: 0.96\n",
            "\n",
            "Best C value: 0.1\n"
          ]
        }
      ],
      "source": [
        "# Defining the chosen beta value\n",
        "beta = 0.5  # Other values can be chosen depending on the emphasis you want to give to precision or recall\n",
        "\n",
        "# Create a placeholder for the best F_beta score and best C value\n",
        "best_f_beta = -1\n",
        "best_c = None\n",
        "\n",
        "# Iterate over the trained models and calculate the metrics on the validation set\n",
        "for i, model in enumerate(models):\n",
        "    # Predict the classes using the current model\n",
        "    y_pred_valid = model.predict(X_valid_std)\n",
        "\n",
        "    # Calculate the error rate\n",
        "    error_rate_valid = 1 - accuracy_score(y_valid, y_pred_valid)\n",
        "\n",
        "    # Calculate the precision and recall\n",
        "    precision_valid = precision_score(y_valid, y_pred_valid, pos_label='ncp')\n",
        "    recall_valid = recall_score(y_valid, y_pred_valid, pos_label='ncp')\n",
        "\n",
        "    # Calculate the F_beta measure\n",
        "    f_beta = (1 + beta**2) * (precision_valid * recall_valid) / ((beta**2 * precision_valid) + recall_valid)\n",
        "\n",
        "    # Update the best F_beta score and best C value\n",
        "    if f_beta > best_f_beta:\n",
        "        best_f_beta = f_beta\n",
        "        best_c = C_values[i]\n",
        "\n",
        "    print(f\"For C = {C_values[i]}:\")\n",
        "    print(f\"  (a) Error rate on validation set: {error_rate_valid:.2f}\")\n",
        "    print(f\"  (b) Precision: {precision_valid:.2f}, Recall: {recall_valid:.2f}\")\n",
        "    print(f\"  (c) F_{beta} measure: {f_beta:.2f}\\n\")\n",
        "\n",
        "# Print the best C value\n",
        "print(f\"Best C value: {best_c}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62b5f6ca",
      "metadata": {
        "id": "62b5f6ca"
      },
      "source": [
        "As $\\beta$ in $F_{\\beta}$, 0.5 was chosen due to the specifics of the task. As we aim to localize the protein, performing a classification task on finding the localization site. As the cost of misclassifying a protein to the wrong location is high due to medical risks, we priotize precision over recall. In medical diagnosis tasks as protein localization, it is prioritized to avoid false positives over identifying all possible true positives because false positive diagnosis can lead to unnecessary treatment or surgery, so it may be more important to obtain a high precision in order to avoid false positives.\n",
        "\n",
        "$\\beta = 0.5$ prioritizes precision so this is why it was chosen."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac3adbb",
      "metadata": {
        "id": "fac3adbb"
      },
      "source": [
        "## 6. Choose 3-5 candidates for C : $C_{1}^{'}, C_{2}^{'}, C_{3}^{'}, C_{4}^{'}, C_{5}^{'}$ and find weight vectors (using only training set) for Models II-IV (with polynomial, radial basis function, sigmoid kernels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "691ff7a6",
      "metadata": {
        "id": "691ff7a6"
      },
      "outputs": [],
      "source": [
        "# Candidate C values\n",
        "C_values_prime = [0.1, 1, 10, 100, 1000]\n",
        "\n",
        "# Kernels\n",
        "kernels = ['poly', 'rbf', 'sigmoid']\n",
        "\n",
        "# Create a dictionary to store the models for each kernel\n",
        "models_by_kernel = {}\n",
        "\n",
        "# Train a model for each candidate C value and kernel\n",
        "for kernel in kernels:\n",
        "    models = []\n",
        "    for C in C_values_prime:\n",
        "        # Create an SVM model with the current kernel and C value\n",
        "        model = SVC(kernel=kernel, C=C, random_state=1) # Using the most standard case for each kernel\n",
        "\n",
        "        # Train the model using the standardized training data\n",
        "        model.fit(X_train_std, y_train)\n",
        "\n",
        "        # Add the trained model to the list of models\n",
        "        models.append(model)\n",
        "\n",
        "    # Store the models for the current kernel\n",
        "    models_by_kernel[kernel] = models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeccac5b",
      "metadata": {
        "id": "aeccac5b",
        "outputId": "5ea4f79d-483b-49f6-934e-5b622da2b2d7"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "coef_ is only available when using a linear kernel",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3880\\656493574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Print weight vectors for the polynomial kernel models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_by_kernel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'poly'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Weight vector for polynomial kernel with C = {C_values_prime[i]}:\\n{model.coef_}\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mcoef_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m         \"\"\"\n\u001b[0;32m    636\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"coef_ is only available when using a linear kernel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_coef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: coef_ is only available when using a linear kernel"
          ]
        }
      ],
      "source": [
        "# Print weight vectors for the polynomial kernel models\n",
        "for i, model in enumerate(models_by_kernel['poly']):\n",
        "    print(f\"Weight vector for polynomial kernel with C = {C_values_prime[i]}:\\n{model.coef_}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21461338",
      "metadata": {
        "id": "21461338",
        "outputId": "6bf607ba-fa57-4e7d-f319-34af82452017"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "coef_ is only available when using a linear kernel",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3880\\4122111653.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Print weight vectors for the polynomial kernel models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_by_kernel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Weight vector for polynomial kernel with C = {C_values_prime[i]}:\\n{model.coef_}\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mcoef_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m         \"\"\"\n\u001b[0;32m    636\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"coef_ is only available when using a linear kernel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_coef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: coef_ is only available when using a linear kernel"
          ]
        }
      ],
      "source": [
        "# Print weight vectors for the polynomial kernel models\n",
        "for i, model in enumerate(models_by_kernel['rbf']):\n",
        "    print(f\"Weight vector for polynomial kernel with C = {C_values_prime[i]}:\\n{model.coef_}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0ea8ffc",
      "metadata": {
        "id": "d0ea8ffc",
        "outputId": "cdd40bc1-96ee-4c83-f652-0ad9c1aa2ac3"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "coef_ is only available when using a linear kernel",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3880\\3581618693.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Print weight vectors for the polynomial kernel models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_by_kernel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Weight vector for polynomial kernel with C = {C_values_prime[i]}:\\n{model.coef_}\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mcoef_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m         \"\"\"\n\u001b[0;32m    636\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"coef_ is only available when using a linear kernel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_coef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: coef_ is only available when using a linear kernel"
          ]
        }
      ],
      "source": [
        "# Print weight vectors for the polynomial kernel models\n",
        "for i, model in enumerate(models_by_kernel['sigmoid']):\n",
        "    print(f\"Weight vector for polynomial kernel with C = {C_values_prime[i]}:\\n{model.coef_}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e999582",
      "metadata": {
        "id": "7e999582"
      },
      "source": [
        "As we can see, computing weights for kernels other than 'linear' is not an easy task due to the fact that attribute \".coef_\" exists only for linear kernels.\n",
        "\n",
        "For other kernels, we approximate the weights using the dual coefficients and support vectors. As the weight vector can be thought of as a combination of the support vectors and their corresponding coefficients coming from solving the dual optimization problem.\n",
        "\n",
        "Even though we know that for an RBF kernel, weights can never be computed analytically due to the fact that it is infinite-dimensional, it can be attempted to give approximate weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5469610f",
      "metadata": {
        "id": "5469610f",
        "outputId": "afd9cb34-4e68-41ed-ea35-2b53212352a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weight vector for polynomial kernel with C = 0.1:\n",
            "[[6.11673090e+00 4.90609401e+00 3.45413690e-02 2.99651530e-04\n",
            "  3.49126375e+00 8.36120777e+00 4.37239392e+00]]\n",
            "\n",
            "Weight vector for polynomial kernel with C = 1:\n",
            "[[2.53351388e+01 2.15672285e+01 4.63619950e-02 1.42272538e-03\n",
            "  1.37026709e+01 3.57876593e+01 1.20163449e+01]]\n",
            "\n",
            "Weight vector for polynomial kernel with C = 10:\n",
            "[[1.06571989e+02 5.75137455e+01 9.55843636e-03 4.67633027e-03\n",
            "  5.45822892e+01 1.04865036e+02 3.24252515e+01]]\n",
            "\n",
            "Weight vector for polynomial kernel with C = 100:\n",
            "[[5.17823898e+02 1.53884198e+02 3.72582850e-03 8.23082616e-03\n",
            "  7.03957531e+01 3.07570496e+02 4.22313017e+01]]\n",
            "\n",
            "Weight vector for polynomial kernel with C = 1000:\n",
            "[[2.07134942e+03 8.68682543e+02 1.90303939e-02 4.20405459e-02\n",
            "  4.38304519e+02 1.00883749e+03 7.02402472e+02]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "w_poly = []\n",
        "for model in models_by_kernel['poly']:\n",
        "    support_vectors = model.support_vectors_\n",
        "    coefficients = model.dual_coef_\n",
        "    w_poly.append(np.dot(coefficients, support_vectors))\n",
        "\n",
        "for i, model in enumerate(models_by_kernel['poly']):\n",
        "    print(f\"Weight vector for polynomial kernel with C = {C_values_prime[i]}:\\n{w_poly[i]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c1f3d6",
      "metadata": {
        "id": "27c1f3d6",
        "outputId": "0051a3e9-e7b5-4c4b-f1e8-50d09f0eb77b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weight vector for rbf kernel with C = 0.1:\n",
            "[[3.4010435  3.57652696 2.94239167 1.30002303 1.71476566 4.90132057\n",
            "  1.30712411]]\n",
            "\n",
            "Weight vector for rbf kernel with C = 1:\n",
            "[[3.75763273 4.91617027 2.27258179 1.89706467 0.66197202 8.68843232\n",
            "  0.80854985]]\n",
            "\n",
            "Weight vector for rbf kernel with C = 10:\n",
            "[[ 6.41023967  8.19403648  2.29455689  1.94811612  1.63240696 12.42305856\n",
            "  -3.05466299]]\n",
            "\n",
            "Weight vector for rbf kernel with C = 100:\n",
            "[[ 1.76659005e+01  2.91766842e+01  2.13162821e-14 -1.68753900e-14\n",
            "   9.89209203e-01  2.02024926e+01 -3.38419437e+00]]\n",
            "\n",
            "Weight vector for rbf kernel with C = 1000:\n",
            "[[ 3.27744261e+01  7.83450356e+01  0.00000000e+00 -1.42108547e-14\n",
            "   5.77017677e+00  4.52082041e+01 -1.43484395e+01]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "w_rbf = []\n",
        "for model in models_by_kernel['rbf']:\n",
        "    support_vectors = model.support_vectors_\n",
        "    coefficients = model.dual_coef_\n",
        "    w_rbf.append(np.dot(coefficients, support_vectors))\n",
        "\n",
        "for i, model in enumerate(models_by_kernel['rbf']):\n",
        "    print(f\"Weight vector for rbf kernel with C = {C_values_prime[i]}:\\n{w_rbf[i]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a2a3b59",
      "metadata": {
        "id": "6a2a3b59",
        "outputId": "0eeadde4-9c77-413d-e86a-f67a65fa4456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weight vector for sigmoid kernel with C = 0.1:\n",
            "[[2.543242   3.05363792 1.17695667 1.30002303 1.29240835 4.00956398\n",
            "  0.60788682]]\n",
            "\n",
            "Weight vector for sigmoid kernel with C = 1:\n",
            "[[ 3.67533304e+00  5.82407356e+00  8.32667268e-17 -1.52655666e-16\n",
            "   1.70548964e+00  8.66355873e+00 -1.05973251e-01]]\n",
            "\n",
            "Weight vector for sigmoid kernel with C = 10:\n",
            "[[ 1.99457606e+00  6.76288588e+00 -8.88178420e-16 -4.44089210e-16\n",
            "  -1.65014246e+00  2.57473499e+01 -9.44865460e+00]]\n",
            "\n",
            "Weight vector for sigmoid kernel with C = 100:\n",
            "[[ 9.81753286e+01  2.51912099e+02  0.00000000e+00  5.32907052e-15\n",
            "   9.68121962e+01  2.77951405e+02 -1.63458706e+02]]\n",
            "\n",
            "Weight vector for sigmoid kernel with C = 1000:\n",
            "[[ 1.34483350e+03  3.36214311e+03 -1.13686838e-13 -1.42108547e-13\n",
            "  -1.25816099e+03  3.15542865e+03 -1.05449099e+03]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "w_sigmoid = []\n",
        "for model in models_by_kernel['sigmoid']:\n",
        "    support_vectors = model.support_vectors_\n",
        "    coefficients = model.dual_coef_\n",
        "    w_sigmoid.append(np.dot(coefficients, support_vectors))\n",
        "\n",
        "for i, model in enumerate(models_by_kernel['sigmoid']):\n",
        "    print(f\"Weight vector for sigmoid kernel with C = {C_values_prime[i]}:\\n{w_sigmoid[i]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32572d63",
      "metadata": {
        "id": "32572d63"
      },
      "source": [
        "## 5. For a Model $\\alpha$, where $\\alpha$ = II-IV do the following: (a) For $C = C_{i}^{'}$, find a solution $\\Lambda_{\\alpha,C_{i}^{'}}^{*}$ for Wolfe dual problem (using only training set). (b) Make estimations as at steps 2-3. Using this estimations, choose the best values $C = C_{\\alpha}^{'}$ for each of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de82470a",
      "metadata": {
        "id": "de82470a",
        "outputId": "7e6a624b-18aa-4c11-bd19-208d3323e3ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel: poly\n",
            "  For C = 0.1:\n",
            "    (a) Dual coefficients: [[-1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -3.85873334e-02 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01 -1.00000000e-01 -1.00000000e-01\n",
            "  -1.00000000e-01 -1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.45701607e-02\n",
            "   1.81475651e-02  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  5.84655791e-03\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   2.30497093e-05  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
            "   1.00000000e-01  1.00000000e-01  1.00000000e-01]]\n",
            "    (b) Training set: Error rate: 0.14, Precision: 0.83, Recall: 0.96\n",
            "        Validation set: Error rate: 0.14, Precision: 0.81, Recall: 1.00, F_0.5 measure: 0.84\n",
            "\n",
            "  For C = 1:\n",
            "    (a) Dual coefficients: [[-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -2.28320500e-01\n",
            "  -1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.02321599e-01\n",
            "  -1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -6.19668466e-01 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
            "   1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
            "   1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
            "   1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
            "   8.65904651e-01  5.76518874e-01  1.00000000e+00  1.00000000e+00\n",
            "   1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
            "   1.00000000e+00  1.00000000e+00  1.00000000e+00  7.76884563e-03\n",
            "   1.00000000e+00  2.49930988e-01  1.00000000e+00  1.00000000e+00\n",
            "   1.00000000e+00  5.60806253e-01  1.00000000e+00  1.00000000e+00\n",
            "   1.00000000e+00  1.09438475e-04  6.89271514e-01  1.00000000e+00\n",
            "   1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
            "   1.00000000e+00  1.00000000e+00]]\n",
            "    (b) Training set: Error rate: 0.05, Precision: 1.00, Recall: 0.91\n",
            "        Validation set: Error rate: 0.07, Precision: 1.00, Recall: 0.88, F_0.5 measure: 0.97\n",
            "\n",
            "  For C = 10:\n",
            "    (a) Dual coefficients: [[-1.00000000e+01 -1.00000000e+01 -1.00000000e+01 -1.00000000e+01\n",
            "  -1.00000000e+01 -1.00000000e+01 -1.00000000e+01 -1.00000000e+01\n",
            "  -7.02991529e+00 -1.00000000e+01 -1.00000000e+01 -1.00000000e+01\n",
            "  -1.00000000e+01 -1.00000000e+01 -1.00000000e+01 -1.00000000e+01\n",
            "  -2.66896739e+00 -1.00000000e+01 -8.70612532e+00 -1.00000000e+01\n",
            "  -1.00000000e+01  1.00000000e+01  1.00000000e+01  1.00000000e+01\n",
            "   1.00000000e+01  1.00000000e+01  1.00000000e+01  6.55842651e+00\n",
            "   3.52869754e+00  2.27986924e+00  3.15507125e+00  1.00000000e+01\n",
            "   7.19214484e-01  3.65117585e-02  1.00000000e+01  1.00000000e+01\n",
            "   1.00000000e+01  1.26455175e-03  1.00000000e+01  1.83278251e+00\n",
            "   1.00000000e+01  1.00000000e+01  3.59711340e-04  1.00000000e+01\n",
            "   7.67799666e+00  1.00000000e+01  2.61481378e+00  1.00000000e+01\n",
            "   1.00000000e+01]]\n",
            "    (b) Training set: Error rate: 0.04, Precision: 1.00, Recall: 0.94\n",
            "        Validation set: Error rate: 0.08, Precision: 1.00, Recall: 0.86, F_0.5 measure: 0.97\n",
            "\n",
            "  For C = 100:\n",
            "    (a) Dual coefficients: [[-1.00000000e+02 -4.84255393e+01 -1.51554325e+01 -6.20916877e+01\n",
            "  -2.70754082e+00 -1.00000000e+02 -6.96771729e-01 -7.62162572e+01\n",
            "  -1.00000000e+02 -1.00000000e+02 -6.64156252e+01 -1.00000000e+02\n",
            "  -1.00000000e+02 -1.00000000e+02 -1.00000000e+02  9.72666527e+01\n",
            "   1.00000000e+02  1.00000000e+02  1.00000000e+02  2.55148416e+01\n",
            "   5.54762834e-01  2.84466577e+01  1.00000000e+02  1.42193716e+01\n",
            "   1.00000000e+02  6.06607154e+00  1.00000000e+02  1.00000000e+02\n",
            "   6.33129257e-04  4.43914248e+01  5.52484385e+01  1.00000000e+02]]\n",
            "    (b) Training set: Error rate: 0.03, Precision: 1.00, Recall: 0.95\n",
            "        Validation set: Error rate: 0.06, Precision: 1.00, Recall: 0.90, F_0.5 measure: 0.98\n",
            "\n",
            "  For C = 1000:\n",
            "    (a) Dual coefficients: [[-1.00000000e+03 -5.65831892e+01 -1.29006138e+01 -2.36692163e+01\n",
            "  -1.49422175e+02 -2.34530362e+02 -1.00000000e+03 -6.18594603e+02\n",
            "  -1.19131062e+02 -2.39388157e+02 -1.00000000e+03 -2.96207882e+02\n",
            "  -2.92570474e+02 -1.00000000e+03 -6.07786852e+02  3.22113087e+02\n",
            "   6.77030158e+02  1.00000000e+03  1.01747840e+02  2.65836518e+00\n",
            "   1.00000000e+03  1.14534653e+02  7.96940042e+02  2.90708614e+01\n",
            "   1.00000000e+03  3.28510338e+02  3.23383086e-03  8.44089639e+01\n",
            "   1.93767044e+02  1.00000000e+03]]\n",
            "    (b) Training set: Error rate: 0.02, Precision: 0.99, Recall: 0.97\n",
            "        Validation set: Error rate: 0.11, Precision: 0.96, Recall: 0.86, F_0.5 measure: 0.94\n",
            "\n",
            "  Best C value for poly kernel: 100\n",
            "\n",
            "Kernel: rbf\n",
            "  For C = 0.1:\n",
            "    (a) Dual coefficients: [[-0.1        -0.1        -0.1        -0.1        -0.1        -0.1\n",
            "  -0.1        -0.1        -0.1        -0.1        -0.1        -0.1\n",
            "  -0.1        -0.1        -0.1        -0.1        -0.1        -0.1\n",
            "  -0.1        -0.1        -0.1        -0.1        -0.1        -0.1\n",
            "  -0.1        -0.1        -0.1        -0.1        -0.01034051 -0.1\n",
            "  -0.1        -0.1        -0.1        -0.1        -0.1        -0.1\n",
            "  -0.1        -0.1        -0.1        -0.1        -0.1        -0.1\n",
            "  -0.1        -0.1        -0.1        -0.1        -0.1        -0.1\n",
            "   0.1         0.1         0.1         0.1         0.1         0.1\n",
            "   0.1         0.08834954  0.1         0.1         0.1         0.1\n",
            "   0.1         0.04622538  0.1         0.1         0.07120523  0.1\n",
            "   0.1         0.1         0.1         0.1         0.1         0.1\n",
            "   0.1         0.1         0.1         0.1         0.1         0.1\n",
            "   0.03189294  0.1         0.1         0.1         0.09185068  0.1\n",
            "   0.1         0.1         0.1         0.08081674  0.1         0.1\n",
            "   0.1         0.1         0.1         0.1         0.1         0.1\n",
            "   0.1       ]]\n",
            "    (b) Training set: Error rate: 0.04, Precision: 0.99, Recall: 0.95\n",
            "        Validation set: Error rate: 0.05, Precision: 0.93, Recall: 1.00, F_0.5 measure: 0.94\n",
            "\n",
            "  For C = 1:\n",
            "    (a) Dual coefficients: [[-0.68849595 -1.         -1.         -1.         -1.         -0.04446363\n",
            "  -1.         -1.         -1.         -1.         -1.         -1.\n",
            "  -1.         -0.56011724 -0.27174863 -0.60650181 -1.         -1.\n",
            "  -1.         -1.          1.          1.          1.          1.\n",
            "   0.71227168  1.          0.32244065  0.55429614  0.04557664  0.07827541\n",
            "   1.          0.86733917  0.02467673  1.          0.11640183  0.48391192\n",
            "   0.18859765  0.17710999  1.          1.          0.14592547  1.\n",
            "   0.73376831  1.          0.72073567  1.        ]]\n",
            "    (b) Training set: Error rate: 0.03, Precision: 0.99, Recall: 0.96\n",
            "        Validation set: Error rate: 0.04, Precision: 0.94, Recall: 1.00, F_0.5 measure: 0.96\n",
            "\n",
            "  For C = 10:\n",
            "    (a) Dual coefficients: [[-1.08074681e+00 -1.00000000e+01 -2.85647403e+00 -1.26107434e+00\n",
            "  -1.00000000e+01 -1.00000000e+01 -1.09393682e+00 -8.14786847e+00\n",
            "  -5.40900668e-02 -6.55503583e+00 -9.79901634e+00 -1.00000000e+01\n",
            "  -6.28036049e-01 -1.00000000e+01  7.12644993e+00  2.42691744e+00\n",
            "   1.00000000e+01  1.00000000e+01  4.52383955e-01  1.75961780e+00\n",
            "   4.65653566e-02  7.49929401e-02  1.00000000e+01  2.26131431e-03\n",
            "   1.16241529e-01  2.40148180e+00  2.27557174e-01  1.00000000e+01\n",
            "   8.78964258e+00  1.49852431e-01  5.08296655e+00  2.81934797e+00\n",
            "   1.00000000e+01]]\n",
            "    (b) Training set: Error rate: 0.03, Precision: 0.99, Recall: 0.96\n",
            "        Validation set: Error rate: 0.04, Precision: 0.96, Recall: 0.98, F_0.5 measure: 0.97\n",
            "\n",
            "  For C = 100:\n",
            "    (a) Dual coefficients: [[-7.65517572e+01 -3.67433987e+00 -8.99266806e+00 -1.43856328e+01\n",
            "  -2.51161634e+01 -8.45525356e+00 -3.09576284e+01 -1.73916178e+00\n",
            "  -8.26967534e+01 -6.35038066e+00 -6.07001230e-02 -4.30999290e+01\n",
            "  -4.13861448e+01 -1.38238740e+01 -3.86184332e+01 -1.00000000e+02\n",
            "  -4.49533667e+01  1.05663693e+01  1.00000000e+02  1.00000000e+02\n",
            "   3.45023402e+00  4.99041092e+00  8.37324088e+01  3.30623669e+00\n",
            "   6.77414707e+00  1.00000000e+02  1.17848234e+01  1.49152968e+01\n",
            "   1.34225994e+00  1.00000000e+02]]\n",
            "    (b) Training set: Error rate: 0.02, Precision: 0.99, Recall: 0.98\n",
            "        Validation set: Error rate: 0.05, Precision: 0.94, Recall: 0.98, F_0.5 measure: 0.95\n",
            "\n",
            "  For C = 1000:\n",
            "    (a) Dual coefficients: [[ -133.15027673   -16.25428064    -4.14821644  -102.67630333\n",
            "   -202.75922989   -75.27385097    -6.49624036    -2.68661179\n",
            "    -29.57837917   -47.10842994  -295.91161355  -284.49212293\n",
            "   -213.90927793   -62.11578949   -27.63401156 -1000.\n",
            "   -108.95579394   192.20709051   603.82778891     5.75876399\n",
            "     21.39893689    19.4030908    600.69928742     5.6389169\n",
            "    150.11230658    14.10424666  1000.        ]]\n",
            "    (b) Training set: Error rate: 0.01, Precision: 1.00, Recall: 0.99\n",
            "        Validation set: Error rate: 0.08, Precision: 0.91, Recall: 0.96, F_0.5 measure: 0.92\n",
            "\n",
            "  Best C value for rbf kernel: 10\n",
            "\n",
            "Kernel: sigmoid\n",
            "  For C = 0.1:\n",
            "    (a) Dual coefficients: [[-0.1        -0.1        -0.1        -0.1        -0.0841614  -0.1\n",
            "  -0.1        -0.1        -0.1        -0.1        -0.1        -0.1\n",
            "  -0.1        -0.1        -0.1        -0.1        -0.1        -0.1\n",
            "  -0.1        -0.1        -0.1        -0.1        -0.1        -0.1\n",
            "  -0.1        -0.1        -0.1        -0.1        -0.1        -0.1\n",
            "  -0.1        -0.1        -0.1        -0.1        -0.1        -0.1\n",
            "  -0.1        -0.1        -0.1        -0.1        -0.1        -0.1\n",
            "  -0.1        -0.1        -0.1         0.1         0.1         0.1\n",
            "   0.1         0.1         0.1         0.1         0.1         0.1\n",
            "   0.1         0.1         0.1         0.05403644  0.1         0.1\n",
            "   0.1         0.03012496  0.1         0.1         0.1         0.1\n",
            "   0.1         0.1         0.1         0.1         0.1         0.1\n",
            "   0.1         0.1         0.1         0.1         0.1         0.1\n",
            "   0.1         0.1         0.1         0.1         0.1         0.1\n",
            "   0.1         0.1         0.1         0.1         0.1         0.1\n",
            "   0.1       ]]\n",
            "    (b) Training set: Error rate: 0.04, Precision: 0.98, Recall: 0.95\n",
            "        Validation set: Error rate: 0.06, Precision: 0.94, Recall: 0.96, F_0.5 measure: 0.95\n",
            "\n",
            "  For C = 1:\n",
            "    (a) Dual coefficients: [[-1.         -1.         -1.         -1.         -0.4751993  -1.\n",
            "  -1.         -1.         -1.         -1.         -1.         -1.\n",
            "  -1.         -1.         -1.         -1.         -1.         -1.\n",
            "  -1.         -1.         -1.          1.          1.          1.\n",
            "   1.          1.          0.09888159  1.          1.          1.\n",
            "   1.          1.          1.          0.39355188  1.          0.0311261\n",
            "   1.          1.          1.          1.          1.          1.\n",
            "   0.95163974  1.        ]]\n",
            "    (b) Training set: Error rate: 0.05, Precision: 0.97, Recall: 0.95\n",
            "        Validation set: Error rate: 0.06, Precision: 0.94, Recall: 0.96, F_0.5 measure: 0.95\n",
            "\n",
            "  For C = 10:\n",
            "    (a) Dual coefficients: [[-10.         -10.          -1.31646154 -10.         -10.\n",
            "  -10.         -10.         -10.         -10.          -8.69683793\n",
            "  -10.         -10.         -10.          10.          10.\n",
            "   10.          10.          10.          10.           0.81352496\n",
            "   10.          10.          10.           9.19977451  10.\n",
            "   10.        ]]\n",
            "    (b) Training set: Error rate: 0.07, Precision: 0.95, Recall: 0.93\n",
            "        Validation set: Error rate: 0.02, Precision: 0.96, Recall: 1.00, F_0.5 measure: 0.97\n",
            "\n",
            "  For C = 100:\n",
            "    (a) Dual coefficients: [[ -50.05823829 -100.         -100.         -100.         -100.\n",
            "   -62.06661825   -4.75696923 -100.         -100.          100.\n",
            "    45.71794118  100.          100.           71.16388459  100.\n",
            "   100.          100.        ]]\n",
            "    (b) Training set: Error rate: 0.07, Precision: 0.94, Recall: 0.94\n",
            "        Validation set: Error rate: 0.11, Precision: 0.88, Recall: 0.96, F_0.5 measure: 0.89\n",
            "\n",
            "  For C = 1000:\n",
            "    (a) Dual coefficients: [[ -123.79424736 -1000.         -1000.         -1000.\n",
            "  -1000.         -1000.         -1000.         -1000.\n",
            "  -1000.          1000.          1000.          1000.\n",
            "   1000.           804.3190903    106.52926708   827.65566031\n",
            "    385.29022966  1000.          1000.        ]]\n",
            "    (b) Training set: Error rate: 0.08, Precision: 0.92, Recall: 0.94\n",
            "        Validation set: Error rate: 0.07, Precision: 0.91, Recall: 0.98, F_0.5 measure: 0.92\n",
            "\n",
            "  Best C value for sigmoid kernel: 10\n",
            "\n"
          ]
        }
      ],
      "source": [
        "beta = 0.5\n",
        "\n",
        "# Iterate over the kernels and trained models\n",
        "for kernel, models in models_by_kernel.items():\n",
        "    print(f\"Kernel: {kernel}\")\n",
        "\n",
        "    best_f_beta = -1\n",
        "    best_c = None\n",
        "\n",
        "    for i, model in enumerate(models):\n",
        "        # Access the dual coefficients\n",
        "        dual_coefs = model.dual_coef_\n",
        "\n",
        "        # Calculate metrics for the training set\n",
        "        y_pred_train = model.predict(X_train_std)\n",
        "        error_rate_train = 1 - accuracy_score(y_train, y_pred_train)\n",
        "        precision_train = precision_score(y_train, y_pred_train, pos_label='ncp')\n",
        "        recall_train = recall_score(y_train, y_pred_train, pos_label='ncp')\n",
        "\n",
        "        # Calculate metrics for the validation set\n",
        "        y_pred_valid = model.predict(X_valid_std)\n",
        "        error_rate_valid = 1 - accuracy_score(y_valid, y_pred_valid)\n",
        "        precision_valid = precision_score(y_valid, y_pred_valid, pos_label='ncp')\n",
        "        recall_valid = recall_score(y_valid, y_pred_valid, pos_label='ncp')\n",
        "        f_beta_valid = (1 + beta**2) * (precision_valid * recall_valid) / ((beta**2 * precision_valid) + recall_valid)\n",
        "\n",
        "        # Update the best F_beta score and best C value if needed\n",
        "        if f_beta_valid > best_f_beta:\n",
        "            best_f_beta = f_beta_valid\n",
        "            best_c = C_values_prime[i]\n",
        "\n",
        "        # Print the results\n",
        "        print(f\"  For C = {C_values_prime[i]}:\")\n",
        "        print(f\"    (a) Dual coefficients: {dual_coefs}\")\n",
        "        print(f\"    (b) Training set: Error rate: {error_rate_train:.2f}, Precision: {precision_train:.2f}, Recall: {recall_train:.2f}\")\n",
        "        print(f\"        Validation set: Error rate: {error_rate_valid:.2f}, Precision: {precision_valid:.2f}, Recall: {recall_valid:.2f}, F_{beta} measure: {f_beta_valid:.2f}\\n\")\n",
        "\n",
        "    # Print the best C value for the current kernel\n",
        "    print(f\"  Best C value for {kernel} kernel: {best_c}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "595cdbca",
      "metadata": {
        "id": "595cdbca"
      },
      "source": [
        "## 6. For a Model $\\alpha$, where $\\alpha$ = I-IV  and $C = C_{\\alpha}^{*}$, estimate on the test set: (a) percent of incorrectly classified examples (b) precision and recall (c) $F_{\\beta}$ Make a decision, which one of all models is the best one. Explain your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21ce2de5",
      "metadata": {
        "id": "21ce2de5",
        "outputId": "0cf97a59-5659-4770-9f92-96a63f42f2d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel: linear\n",
            "  (a) Error rate on test set: 0.02\n",
            "  (b) Precision: 0.98, Recall: 0.98\n",
            "  (c) F_0.5 measure: 0.98\n",
            "\n",
            "Kernel: poly\n",
            "  (a) Error rate on test set: 0.12\n",
            "  (b) Precision: 0.83, Recall: 0.98\n",
            "  (c) F_0.5 measure: 0.86\n",
            "\n",
            "Kernel: rbf\n",
            "  (a) Error rate on test set: 0.02\n",
            "  (b) Precision: 0.98, Recall: 0.98\n",
            "  (c) F_0.5 measure: 0.98\n",
            "\n",
            "Kernel: sigmoid\n",
            "  (a) Error rate on test set: 0.02\n",
            "  (b) Precision: 0.98, Recall: 0.98\n",
            "  (c) F_0.5 measure: 0.98\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Best C values obtained in previous steps\n",
        "best_c_linear = best_c\n",
        "best_c_poly = models_by_kernel['poly'][0].C\n",
        "best_c_rbf = models_by_kernel['rbf'][0].C\n",
        "best_c_sigmoid = models_by_kernel['sigmoid'][0].C\n",
        "\n",
        "# Train the best models with the selected C values\n",
        "best_models = [\n",
        "    ('linear', SVC(kernel='linear', C=best_c_linear, random_state=1).fit(X_train_std, y_train)),\n",
        "    ('poly', SVC(kernel='poly', C=best_c_poly, random_state=1).fit(X_train_std, y_train)),\n",
        "    ('rbf', SVC(kernel='rbf', C=best_c_rbf, random_state=1).fit(X_train_std, y_train)),\n",
        "    ('sigmoid', SVC(kernel='sigmoid', C=best_c_sigmoid, random_state=1).fit(X_train_std, y_train))\n",
        "]\n",
        "\n",
        "beta = 0.5 #chosen beta\n",
        "\n",
        "# Evaluate the models on the test set\n",
        "for kernel, model in best_models:\n",
        "    y_pred_test = model.predict(X_test_std)\n",
        "\n",
        "    # Calculate the error rate, precision, recall, and F_beta measure\n",
        "    error_rate_test = 1 - accuracy_score(y_test, y_pred_test)\n",
        "    precision_test = precision_score(y_test, y_pred_test, pos_label='ncp')\n",
        "    recall_test = recall_score(y_test, y_pred_test, pos_label='ncp')\n",
        "    f_beta_test = (1 + beta**2) * (precision_test * recall_test) / ((beta**2 * precision_test) + recall_test)\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Kernel: {kernel}\")\n",
        "    print(f\"  (a) Error rate on test set: {error_rate_test:.2f}\")\n",
        "    print(f\"  (b) Precision: {precision_test:.2f}, Recall: {recall_test:.2f}\")\n",
        "    print(f\"  (c) F_{beta} measure: {f_beta_test:.2f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53f81198",
      "metadata": {
        "id": "53f81198"
      },
      "source": [
        "Based on the performance metrics (error rate, precision, recall, and $F_\\beta$ measure) on the test set, we decide which model is the best one.\n",
        "\n",
        "The best model has the lowest error rate and highest $F_\\beta$ measure. In my specific problem, high precision value is also prioritized.\n",
        "\n",
        "Due to error rate and $F_\\beta$ score, we eliminate the polynomial kernel.\n",
        "\n",
        "Linear kernel is preferrable due to interpretability due to ability to directly obtain the weight vector, while RBF kernel is better in capturing complex non-linear relationships between the input features and the output variable. Sigmoid kernel is also good at capturing non-linear relationships, but it is too sensitive to hyperparameter choice and computationally more expensive than the other two. So, we eliminate the sigmoid kernel as well.\n",
        "\n",
        "Since both linear and rbf kernels give the same performance, I would choose linear due to its simplicity and interpretability as interpretability of results is very important in studies involving the medicine and biological sciences."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}